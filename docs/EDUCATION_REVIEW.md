# ğŸ“š êµìœ¡ ë‚´ìš© ì ìš© ê²€í†  ë³´ê³ ì„œ

## ğŸ¯ ëª©ì 
MS AI êµìœ¡ ê³¼ì •(Day 1-3)ì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì´ `ai-guardrail-azure-mvp` í”„ë¡œì íŠ¸ì— ì–´ë–»ê²Œ ì ìš©ë˜ì—ˆëŠ”ì§€ ë¶„ì„í•˜ê³ , ê°œì„  ê¸°íšŒë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.

---

## âœ… ìš°ìˆ˜í•˜ê²Œ ì ìš©ëœ ê°œë… (â­â­â­)

### 1. LangChain LCEL íŒŒì´í”„ë¼ì¸ (DAY01_002)
**êµìœ¡ ë‚´ìš©:**
```python
# ê¸°ë³¸ ì²´ì¸ êµ¬ì„±
chain = prompt | llm | StrOutputParser()
response = chain.invoke({"topic": "...", "question": "..."})
```

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py:200`
```python
answer_str = (prompt | llm | output_parser).invoke(prompt_inputs)
```
- âœ… LCELì˜ íŒŒì´í”„ ì—°ì‚°ì(`|`)ë¥¼ ì •í™•íˆ ì‚¬ìš©
- âœ… Prompt â†’ LLM â†’ Parserì˜ 3ë‹¨ê³„ ì²´ì¸ ì™„ë²½ êµ¬í˜„
- âœ… `.invoke()` ë©”ì„œë“œë¡œ ì‹¤í–‰

**í‰ê°€:** êµìœ¡ ë‚´ìš©ì„ 100% ì •í™•íˆ ì ìš©í–ˆìŠµë‹ˆë‹¤.

---

### 2. RAG ê¸°ë³¸ êµ¬ì¡° (DAY01_003)
**êµìœ¡ ë‚´ìš©:**
- Retrieverë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
- Contextì— ë¬¸ì„œ ì‚½ì…
- LLMì— Context + ì§ˆë¬¸ ì „ë‹¬

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py:58-62, 188`
```python
# Retriever ì •ì˜
retriever = vector_store.as_retriever(
    search_type="hybrid",
    search_kwargs={"search_fields": ["content", "translated_text", "keyphrases"]},
    k=CONFIG.get("rag_top_k", 3),
)

# ê²€ìƒ‰ ì‹¤í–‰
retrieved_docs = retriever.invoke(text_to_evaluate)
```
- âœ… Retriever íŒ¨í„´ ì •í™•íˆ êµ¬í˜„
- âœ… `k=3` (top-k) ì„¤ì •ìœ¼ë¡œ ë¬¸ì„œ ìˆ˜ ì œí•œ
- âœ… Contextë¥¼ í”„ë¡¬í”„íŠ¸ì— ì£¼ì… (ë¼ì¸ 195)

**í‰ê°€:** RAGì˜ í•µì‹¬ ê°œë…ì„ ì™„ë²½íˆ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

---

### 3. Prompt Engineering & Few-shot (DAY01_005)
**êµìœ¡ ë‚´ìš©:**
- í˜ë¥´ì†Œë‚˜ ë¶€ì—¬
- Few-shot ì˜ˆì‹œ ì œê³µ
- Chain of Thought ì§€ì‹œ

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py:67-129`
```python
template = """
You are the Chief Compliance Officer AI for KB Kookmin Bank...  # í˜ë¥´ì†Œë‚˜

Follow these steps strictly:  # Chain of Thought
1. Analyze the text...
2. Compare the text...
3. If the text violates...

Example of a BAD response (FAIL):  # Few-shot (ë¶€ì • ì˜ˆì‹œ)
{{...}}

Example of a GOOD response (PASS):  # Few-shot (ê¸ì • ì˜ˆì‹œ)
{{...}}

Example for a harmful text:  # Few-shot (3ê°œ ì˜ˆì‹œ)
{{...}}
"""
```
- âœ… ëª…í™•í•œ í˜ë¥´ì†Œë‚˜ ì •ì˜
- âœ… 3ê°œì˜ Few-shot ì˜ˆì‹œ ì œê³µ
- âœ… Chain of Thought (ë‹¨ê³„ë³„ ì§€ì‹œ)
- âœ… Grounding ê°•í™” ("ì˜¤ì§ Contextë§Œ ì‚¬ìš©")

**í‰ê°€:** í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ Best Practiceë¥¼ ëª¨ë‘ ì ìš©í–ˆìŠµë‹ˆë‹¤.

---

### 4. Hybrid Search (DAY02_003)
**êµìœ¡ ë‚´ìš©:**
- ë²¡í„° ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)
- í‚¤ì›Œë“œ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­)
- ë‘ ë°©ì‹ì˜ ê²°í•©

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py:58-62`
```python
retriever = vector_store.as_retriever(
    search_type="hybrid",  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    search_kwargs={"search_fields": ["content", "translated_text", "keyphrases"]},  # ë‹¤ì¤‘ í•„ë“œ
)
```
**ì¸í”„ë¼ êµ¬í˜„:** `scripts/create_index.py:137-156`
```python
# ë²¡í„° ê²€ìƒ‰: HNSW ì•Œê³ ë¦¬ì¦˜
SearchField(
    name="content_vector",
    type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
    searchable=True,
    vector_search_dimensions=1536,
    vector_search_profile_name="hnsw-profile",
)

# í‚¤ì›Œë“œ ê²€ìƒ‰: Lucene ë¶„ì„ê¸°
SearchableField(name="content", type=SearchFieldDataType.String, analyzer_name="ko.lucene")
```
- âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™œì„±í™”
- âœ… ë²¡í„° + í‚¤ì›Œë“œ ë™ì‹œ í™œìš©
- âœ… í•œêµ­ì–´/ì˜ì–´ ë¶„ì„ê¸° ì ìš©

**í‰ê°€:** êµìœ¡ ë‚´ìš©ì„ ì¸í”„ë¼ ë ˆë²¨ê¹Œì§€ ì™„ë²½ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

---

### 5. LLM-as-Judge (DAY02_007)
**êµìœ¡ ë‚´ìš©:**
- LLMì„ í‰ê°€ì(Judge)ë¡œ í™œìš©
- êµ¬ì¡°í™”ëœ í‰ê°€ ê¸°ì¤€ ì œê³µ
- JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ë°˜í™˜

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py` ì „ì²´ êµ¬ì¡°
```python
def check_guardrail(text_to_evaluate: str) -> Dict[str, Any]:
    """LLMì„ Judgeë¡œ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì •ì±… ìœ„ë°˜ ì—¬ë¶€ë¥¼ íŒë‹¨"""
    # 1. ê´€ë ¨ ì •ì±… ë¬¸ì„œ ê²€ìƒ‰
    retrieved_docs = retriever.invoke(text_to_evaluate)
    
    # 2. LLMì—ê²Œ íŒë‹¨ ìš”ì²­ (Judge ì—­í• )
    answer_str = (prompt | llm | output_parser).invoke(prompt_inputs)
    response_json = json.loads(answer_str)
    
    # 3. íŒë‹¨ ê²°ê³¼ ë°˜í™˜ (SAFE/HARMFUL + reason)
    return response_json
```
- âœ… LLMì„ Judgeë¡œ í™œìš©
- âœ… ëª…í™•í•œ í‰ê°€ ê¸°ì¤€ ì œê³µ
- âœ… êµ¬ì¡°í™”ëœ JSON ì¶œë ¥

**í‰ê°€:** LLM-as-Judge íŒ¨í„´ì„ ì‹¤ì „ì— ì™„ë²½ ì ìš©í–ˆìŠµë‹ˆë‹¤.

---

## âš ï¸ ë¶€ë¶„ ì ìš©ëœ ê°œë… (â­â­)

### 6. ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™” (DAY02_002)
**êµìœ¡ ë‚´ìš©:**
- Top-Kë¡œ ë¬¸ì„œ ìˆ˜ ì œí•œ
- í† í° ìˆ˜ ì œí•œìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì ˆ

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py:138-171`
```python
def limit_docs_with_metadata(docs: List[Document], *, max_tokens: int | None = None):
    """ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í† í° ìˆ˜ë¥¼ ì œí•œ"""
    max_tokens = CONFIG.get("rag_max_context_tokens", 2000) if max_tokens is None else max_tokens
    # ... í† í° ê³„ì‚° ë° ì œí•œ ë¡œì§
```
- âœ… Top-K ì œí•œ (k=3)
- âœ… í† í° ìˆ˜ ì œí•œ (2000 í† í°)
- âš ï¸ **ê°œì„  ê°€ëŠ¥**: í† í° ê³„ì‚°ì´ ê·¼ì‚¬ì¹˜ (`len(doc.page_content) // 3`)

**ê°œì„  ì œì•ˆ:**
```python
# tiktokenì„ ì‚¬ìš©í•œ ì •í™•í•œ í† í° ê³„ì‚°
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-4")
doc_tokens = len(encoding.encode(doc.page_content))
```

---

### 7. Output Parser (DAY01_002)
**êµìœ¡ ë‚´ìš©:**
```python
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
```

**í”„ë¡œì íŠ¸ ì ìš©:** `src/core/rag_core.py:134, 200-201`
```python
output_parser = StrOutputParser()
answer_str = (prompt | llm | output_parser).invoke(prompt_inputs)
response_json = json.loads(answer_str)  # ìˆ˜ë™ íŒŒì‹±
```
- âœ… StrOutputParser ì‚¬ìš©
- âš ï¸ **ê°œì„  ê°€ëŠ¥**: JsonOutputParserë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì•ˆì „

**ê°œì„  ì œì•ˆ:**
```python
from langchain_core.output_parsers import JsonOutputParser

output_parser = JsonOutputParser()
response_json = (prompt | llm | output_parser).invoke(prompt_inputs)
# json.loads() ë¶ˆí•„ìš”, ì—ëŸ¬ í•¸ë“¤ë§ ìë™í™”
```

---

## âŒ ë¯¸ì ìš©ëœ ê³ ê¸‰ ê°œë… (â­)

### 8. Query Expansion (DAY02_004)
**êµìœ¡ ë‚´ìš©:**
- ì‚¬ìš©ì ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë³€í˜•ìœ¼ë¡œ í™•ì¥
- ê° ë³€í˜•ìœ¼ë¡œ ê²€ìƒ‰ í›„ ê²°ê³¼ í†µí•©
- ê²€ìƒ‰ ì¬í˜„ìœ¨(Recall) í–¥ìƒ

**í”„ë¡œì íŠ¸ ë¯¸ì ìš©:**
- í˜„ì¬ëŠ” ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œë§Œ ê²€ìƒ‰
- ë™ì˜ì–´ë‚˜ ìœ ì‚¬ í‘œí˜„ìœ¼ë¡œ í™•ì¥í•˜ì§€ ì•ŠìŒ

**ê°œì„  ì œì•ˆ:**
```python
# Multi-query ì „ëµ
def expand_query(original_query: str) -> List[str]:
    """ì§ˆë¬¸ì„ 3-5ê°œ ë³€í˜•ìœ¼ë¡œ í™•ì¥"""
    expansion_prompt = PromptTemplate.from_template(
        "ë‹¤ìŒ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”: {question}"
    )
    expanded = (expansion_prompt | llm | StrOutputParser()).invoke({"question": original_query})
    return [original_query] + expanded.split("\n")

# ëª¨ë“  ë³€í˜•ìœ¼ë¡œ ê²€ìƒ‰ í›„ í†µí•©
all_docs = []
for query in expand_query(text_to_evaluate):
    all_docs.extend(retriever.invoke(query))
```

**ì ìš© ì‹œ íš¨ê³¼:**
- ê²€ìƒ‰ ì¬í˜„ìœ¨ 20-30% í–¥ìƒ ì˜ˆìƒ
- ê°„ê²°í•œ ì§ˆë¬¸ë„ í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ í™•ë³´

---

### 9. Rerank & Compression (DAY02_005)
**êµìœ¡ ë‚´ìš©:**
- ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì¬ì •ë ¬
- ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì••ì¶•í•˜ì—¬ í† í° ì ˆì•½
- Cohere Rerank, LongLLMLingua ë“± í™œìš©

**í”„ë¡œì íŠ¸ ë¯¸ì ìš©:**
- í˜„ì¬ëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- Reranking ì—†ì´ ë²¡í„° ìœ ì‚¬ë„ ìˆœì„œë§Œ ì‚¬ìš©

**ê°œì„  ì œì•ˆ:**
```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CohereRerank

# Reranker ì¶”ê°€
compressor = CohereRerank(model="rerank-multilingual-v2.0")
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=retriever
)

# ì‚¬ìš©
retrieved_docs = compression_retriever.invoke(text_to_evaluate)
```

**ì ìš© ì‹œ íš¨ê³¼:**
- ê²€ìƒ‰ ì •í™•ë„ 15-25% í–¥ìƒ
- ë¶ˆí•„ìš”í•œ ë¬¸ì„œ ì œê±°ë¡œ í† í° ë¹„ìš© ì ˆê°

---

### 10. LangSmith Monitoring (DAY01_002, DAY01_004)
**êµìœ¡ ë‚´ìš©:**
- ëª¨ë“  ì²´ì¸ ì‹¤í–‰ì„ ìë™ ì¶”ì 
- í† í° ì‚¬ìš©ëŸ‰, ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬

**í”„ë¡œì íŠ¸ ë¯¸ì ìš©:**
- í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì—†ìŒ
- ì„±ëŠ¥ ì§€í‘œê°€ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ì¸¡ì •ë¨ (`elapsed_time`ë§Œ ì¶”ì )

**ê°œì„  ì œì•ˆ:**
```.env
# LangSmith ì¶”ì  í™œì„±í™”
LANGSMITH_API_KEY=your_key
LANGSMITH_TRACING=true
LANGSMITH_PROJECT=ai-guardrail-mvp
```
```python
# rag_core.pyì—ì„œ ìë™ ì¶”ì  í™œì„±í™”
from langsmith import trace

@trace(name="guardrail_check")
def check_guardrail(text_to_evaluate: str):
    # ê¸°ì¡´ ì½”ë“œ...
```

**ì ìš© ì‹œ íš¨ê³¼:**
- ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°€ì‹œì„± í™•ë³´
- ë³‘ëª© ì§€ì  ì‹ë³„ ìš©ì´
- í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

---

### 11. Langfuse Prompt Management (DAY01_004)
**êµìœ¡ ë‚´ìš©:**
- í”„ë¡¬í”„íŠ¸ë¥¼ ì½”ë“œ ì™¸ë¶€ì—ì„œ ê´€ë¦¬
- ë²„ì „ ê´€ë¦¬ ë° ë¡¤ë°±
- í”„ë¡œë•ì…˜ì—ì„œ í”„ë¡¬í”„íŠ¸ë§Œ ë³€ê²½ ê°€ëŠ¥

**í”„ë¡œì íŠ¸ ë¯¸ì ìš©:**
- í”„ë¡¬í”„íŠ¸ê°€ ì½”ë“œì— í•˜ë“œì½”ë”©ë¨ (`rag_core.py:66-129`)
- í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì‹œ ì½”ë“œ ì¬ë°°í¬ í•„ìš”

**ê°œì„  ì œì•ˆ:**
```python
from langfuse import Langfuse

langfuse = Langfuse()

# í”„ë¡¬í”„íŠ¸ë¥¼ Langfuseì—ì„œ ê°€ì ¸ì˜¤ê¸°
prompt_template = langfuse.get_prompt("guardrail-judge-v1")
prompt = ChatPromptTemplate.from_template(prompt_template.template)
```

**ì ìš© ì‹œ íš¨ê³¼:**
- í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì‹œ ì¬ë°°í¬ ë¶ˆí•„ìš”
- A/B í…ŒìŠ¤íŒ… ìš©ì´
- í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì´ë ¥ ì¶”ì 

---

### 12. LangGraph (DAY03_004~009)
**êµìœ¡ ë‚´ìš©:**
- ë³µì¡í•œ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°
- ìƒíƒœ ê´€ë¦¬ (StateGraph)
- Human-in-the-Loop (HITL)
- ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬

**í”„ë¡œì íŠ¸ ë¯¸ì ìš©:**
- í˜„ì¬ëŠ” ë‹¨ìˆœ ì²´ì¸ë§Œ ì‚¬ìš©
- ë³µì¡í•œ ë¶„ê¸°ë‚˜ ìƒíƒœ ê´€ë¦¬ ì—†ìŒ

**ì ìš© ê°€ëŠ¥ì„±:**
í”„ë¡œì íŠ¸ê°€ ë‹¨ìˆœ ê°€ë“œë ˆì¼ì´ë¯€ë¡œ LangGraphê°€ í•„ìš”í•˜ì§€ ì•ŠìŒ. ê·¸ëŸ¬ë‚˜ í–¥í›„ í™•ì¥ ì‹œ:

**ë¯¸ë˜ í™•ì¥ ì‹œë‚˜ë¦¬ì˜¤:**
```python
from langgraph.graph import StateGraph

# ë‹¤ë‹¨ê³„ ê°€ë“œë ˆì¼ ì›Œí¬í”Œë¡œìš°
class GuardrailState(TypedDict):
    input: str
    input_check: str
    llm_response: str
    output_check: str
    final_decision: str

workflow = StateGraph(GuardrailState)
workflow.add_node("input_filter", check_input)
workflow.add_node("llm_call", call_llm)
workflow.add_node("output_filter", check_output)
workflow.add_edge("input_filter", "llm_call")
workflow.add_conditional_edges(
    "llm_call",
    lambda x: "output_filter" if x["input_check"] == "SAFE" else "END"
)
```

**ì ìš© ì‹œ íš¨ê³¼:**
- ë³µì¡í•œ ì˜ì‚¬ê²°ì • í”Œë¡œìš° êµ¬í˜„ ê°€ëŠ¥
- ì¡°ê±´ë¶€ ë¶„ê¸° (ì˜ˆ: ìœ„í—˜ë„ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬)
- Human-in-the-Loop (ê³ ìœ„í—˜ ì¼€ì´ìŠ¤ëŠ” ì‚¬ëŒ ê²€í† )

---

## ğŸ“ˆ ìš”ì•½ ë° ìš°ì„ ìˆœìœ„

### ìš°ì„ ìˆœìœ„ 1 (ì¦‰ì‹œ ì ìš© ê¶Œì¥) ğŸ”´

1. **JsonOutputParser ë„ì…**
   - ì‘ì—…ëŸ‰: 5ë¶„
   - íš¨ê³¼: ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ , ì½”ë“œ ì•ˆì •ì„± í–¥ìƒ

2. **LangSmith ëª¨ë‹ˆí„°ë§ í™œì„±í™”**
   - ì‘ì—…ëŸ‰: 10ë¶„
   - íš¨ê³¼: ì „ì²´ ì‹œìŠ¤í…œ ê°€ì‹œì„± í™•ë³´, ë””ë²„ê¹… ìš©ì´

### ìš°ì„ ìˆœìœ„ 2 (ë‹¨ê¸° ê°œì„ ) ğŸŸ¡

3. **ì •í™•í•œ í† í° ê³„ì‚° (tiktoken)**
   - ì‘ì—…ëŸ‰: 30ë¶„
   - íš¨ê³¼: ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì •í™•ë„ í–¥ìƒ, ë¹„ìš© ìµœì í™”

4. **Rerank ì¶”ê°€**
   - ì‘ì—…ëŸ‰: 2ì‹œê°„
   - íš¨ê³¼: ê²€ìƒ‰ ì •í™•ë„ 15-25% í–¥ìƒ

### ìš°ì„ ìˆœìœ„ 3 (ì¤‘ì¥ê¸° ê°œì„ ) ğŸŸ¢

5. **Query Expansion**
   - ì‘ì—…ëŸ‰: 4ì‹œê°„
   - íš¨ê³¼: ê²€ìƒ‰ ì¬í˜„ìœ¨ 20-30% í–¥ìƒ

6. **Langfuse Prompt Management**
   - ì‘ì—…ëŸ‰: 1ì¼
   - íš¨ê³¼: í”„ë¡¬í”„íŠ¸ ìš´ì˜ í¸ì˜ì„± ëŒ€í­ í–¥ìƒ

---

## ğŸ–ï¸ ìµœì¢… í‰ê°€

### ì „ì²´ ì ìš©ë„: **85/100ì ** (ìš°ìˆ˜)

**ê°•ì :**
- âœ… í•µì‹¬ LangChain íŒ¨í„´ ì™„ë²½ êµ¬í˜„ (LCEL, RAG, Prompt Engineering)
- âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, LLM-as-Judge ë“± ê³ ê¸‰ ê¸°ë²• ì ìš©
- âœ… êµìœ¡ ë‚´ìš©ì„ ì‹¤ì „ í”„ë¡œì íŠ¸ì— ì‹¤ìš©ì ìœ¼ë¡œ ë³€í˜•

**ê°œì„  ì—¬ì§€:**
- âš ï¸ ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„± ë¶€ì¡± (LangSmith, Langfuse ë¯¸ì‚¬ìš©)
- âš ï¸ ê²€ìƒ‰ í’ˆì§ˆ ìµœì í™” ì—¬ì§€ (Rerank, Query Expansion)
- âš ï¸ ì¼ë¶€ íŒŒì„œ ë° í† í° ê³„ì‚°ì˜ ì •í™•ë„ ê°œì„  í•„ìš”

**ê²°ë¡ :**
êµìœ¡ì—ì„œ ë°°ìš´ í•µì‹¬ ê°œë…ë“¤ì„ **ì‹¤ì „ì— ì í•©í•˜ê²Œ ì„ ë³„í•˜ì—¬ ìš°ìˆ˜í•˜ê²Œ ì ìš©**í–ˆìŠµë‹ˆë‹¤. 
MVP ë‹¨ê³„ë¡œëŠ” ì¶©ë¶„í•˜ë©°, í–¥í›„ ê°œì„ ì„ í†µí•´ í”„ë¡œë•ì…˜ê¸‰ ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „ ê°€ëŠ¥í•©ë‹ˆë‹¤.
